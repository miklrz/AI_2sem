{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8175744761936437\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    # ф-я активации: f(x) = 1 / (1 + e^(-x))\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "\n",
    "import numpy as np\n",
    "class OurNeuralNetwork1:\n",
    "    '''\n",
    "    Данные нейросети:\n",
    "        - три входа\n",
    "        - три нейрона в скрытых слоях (h1, h2, h3)\n",
    "        - выход (o1)\n",
    "    Нейроны имеют идентичные веса и пороги:\n",
    "        - w = [0.5, 0.5, 0.5]\n",
    "        - b = 0\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5])\n",
    "        bias = 0\n",
    "        \n",
    "        # Класс Neuron из предыдущего раздела\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.h3 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "    \n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "        \n",
    "        # Входы для o1 - это выходы h1, h2, h3\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1\n",
    "\n",
    "network = OurNeuralNetwork1()\n",
    "x = np.array([0, 10, 100])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.1 Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8151036049051821\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5])\n",
    "        bias = 0\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.h3 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "    \n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1\n",
    "    \n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2, 3, 4])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.2 Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9050813365686774\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return tanh(total)\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5])\n",
    "        bias = 0\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.h3 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "    \n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1\n",
    "    \n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2, 3, 4])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.3 ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.75\n"
     ]
    }
   ],
   "source": [
    "#Задание №1.2.3\n",
    "#ReLU\n",
    "import numpy as np\n",
    "\n",
    "def ReLU(x):\n",
    "    return max(0.0, x)\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return ReLU(total)\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5])\n",
    "        bias = 0\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.h3 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "    \n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1\n",
    "    \n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2, 3, 4])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmyty\\AppData\\Local\\Temp\\ipykernel_21584\\3005220023.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Actual   Predicted\n",
      "0   Versicolor  Versicolor\n",
      "1       Setosa      Setosa\n",
      "2    Virginica   Virginica\n",
      "3    Virginica   Virginica\n",
      "4       Setosa      Setosa\n",
      "5       Setosa      Setosa\n",
      "6    Virginica   Virginica\n",
      "7   Versicolor   Virginica\n",
      "8    Virginica   Virginica\n",
      "9       Setosa      Setosa\n",
      "10      Setosa      Setosa\n",
      "11  Versicolor  Versicolor\n",
      "12   Virginica   Virginica\n",
      "13  Versicolor  Versicolor\n",
      "14   Virginica   Virginica\n",
      "15  Versicolor  Versicolor\n",
      "16      Setosa      Setosa\n",
      "17      Setosa      Setosa\n",
      "18      Setosa      Setosa\n",
      "19      Setosa      Setosa\n",
      "20      Setosa      Setosa\n",
      "21   Virginica   Virginica\n",
      "22   Virginica   Virginica\n",
      "23  Versicolor  Versicolor\n",
      "24   Virginica   Virginica\n",
      "25   Virginica   Virginica\n",
      "26  Versicolor  Versicolor\n",
      "27  Versicolor  Versicolor\n",
      "28  Versicolor   Virginica\n",
      "29  Versicolor  Versicolor\n",
      "\n",
      "Test Accuracy: 0.933\n",
      "Training Accuracy: 0.992\n",
      "\n",
      "Matrix of Confusion:\n",
      " [[10  0  0]\n",
      " [ 0  8  2]\n",
      " [ 0  0 10]]\n",
      "\n",
      "Loss :  0.05625574952443364\n",
      "Number of Coefs :  2\n",
      "Number of Intercepts :  2\n",
      "Number of Iterations for Which Estimator Run :  547\n",
      "Name of Output Layer Activation Function :  softmax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "url = r'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv'\n",
    "dataset = pd.read_csv(url)\n",
    "\n",
    "X = dataset.iloc[:, :-1].values\n",
    "Y = dataset.iloc[:, -1].values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size = 0.80, test_size = 0.20, stratify = Y, random_state = 123)\n",
    "\n",
    "mlp_classifier = MLPClassifier(max_iter = 1000).fit(X_train, Y_train)\n",
    "Y_pred = mlp_classifier.predict(X_test)\n",
    "\n",
    "df = pd.DataFrame({'Actual': Y_test, 'Predicted': Y_pred})\n",
    "print(df)\n",
    "\n",
    "print(\"\\nTest Accuracy: %.3f\"%mlp_classifier.score(X_test, Y_test))\n",
    "print('Training Accuracy: %.3f'%mlp_classifier.score(X_train, Y_train))\n",
    "print(f\"\\nMatrix of Confusion:\\n {confusion_matrix(Y_test, Y_pred)}\")\n",
    "print(f\"\\nLoss : \", mlp_classifier.loss_)\n",
    "print(f'Number of Coefs : ', len(mlp_classifier.coefs_))\n",
    "print(f'Number of Intercepts : ', len(mlp_classifier.intercepts_))\n",
    "print(f'Number of Iterations for Which Estimator Run : ', mlp_classifier.n_iter_)\n",
    "print(f'Name of Output Layer Activation Function : ', mlp_classifier.out_activation_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 706984608.62\n",
      "R2 score: 0.35\n",
      "4\n",
      "(100, 50)\n",
      "[array([[ 1.51559623e+00, -3.31340045e-25,  1.71242379e+00,\n",
      "         1.77566056e+00,  1.91818871e+00,  1.53609465e+00,\n",
      "        -6.99750518e-18, -1.65933942e-06,  1.79056233e+00,\n",
      "         1.87163426e+00, -6.95703303e-25,  1.88367466e+00,\n",
      "         1.52925110e+00,  1.76522856e+00,  1.60427255e+00,\n",
      "        -3.86110236e-10, -1.32579797e-07,  1.81095053e+00,\n",
      "         1.55256218e+00,  1.83469265e+00,  2.57430977e-02,\n",
      "         1.91943347e+00,  5.35944241e-26, -8.78279876e-18,\n",
      "        -2.22811333e-06,  1.61567276e+00,  1.74486053e+00,\n",
      "        -1.16682595e-01,  1.52584565e+00,  1.90001125e+00,\n",
      "         1.57096074e-23,  1.87073950e+00, -5.14847554e-02,\n",
      "         1.66621049e+00,  1.85384511e+00, -7.51685204e-05,\n",
      "         1.58991569e+00, -5.00362737e-02, -9.75103538e-02,\n",
      "         1.67827953e+00,  1.73761958e+00,  1.80966387e+00,\n",
      "         1.66980840e+00,  1.45087806e+00,  1.86663548e+00,\n",
      "         4.66911030e-20,  1.90778150e+00,  1.83261142e+00,\n",
      "         1.78733394e+00, -6.22634039e-23,  1.71747109e+00,\n",
      "         1.70752850e+00,  1.87024762e+00,  1.74908465e+00,\n",
      "         1.91113475e+00,  1.92483614e+00,  1.74783247e+00,\n",
      "        -7.03822488e-02, -2.97941639e-09,  1.78547281e+00,\n",
      "         1.74283041e+00, -1.51157135e-07,  1.85795379e+00,\n",
      "        -1.12258699e-02,  1.76489200e+00,  1.48145388e+00,\n",
      "         1.73767105e+00,  1.84128762e+00,  1.81326119e+00,\n",
      "        -3.48187420e-02,  1.76596204e+00, -1.79180027e-14,\n",
      "        -1.12937593e-25,  6.07582415e-22,  1.64274333e+00,\n",
      "        -1.75301103e-01,  1.90933655e+00, -2.60589486e-09,\n",
      "         1.61275538e+00,  1.53546962e+00, -1.39062675e-18,\n",
      "         1.66612318e+00,  1.82754873e+00, -3.56511658e-25,\n",
      "         1.92279816e+00,  1.83555738e+00,  1.92883204e+00,\n",
      "         1.72159953e+00,  1.88630489e+00,  1.89315936e+00,\n",
      "         1.74700298e+00,  1.85569783e+00, -5.15175492e-13,\n",
      "         1.92357835e+00,  7.87008410e-14,  1.77458767e+00,\n",
      "         1.75575985e+00,  1.80974890e+00,  1.90769738e+00,\n",
      "         1.72219337e+00]]), array([[ 4.16074473e-19,  6.97223420e-11,  1.67691255e+00, ...,\n",
      "         1.74882066e+00,  1.67680657e+00,  1.74302048e+00],\n",
      "       [ 2.89433166e-25, -1.71161529e-25, -2.04332015e-16, ...,\n",
      "        -1.38854552e-25, -1.99924900e-25,  3.09439522e-17],\n",
      "       [-4.55778032e-02,  2.72878871e-08,  1.81605051e+00, ...,\n",
      "         1.74966066e+00,  1.86947441e+00,  1.95771449e+00],\n",
      "       ...,\n",
      "       [-6.19120169e-04,  9.51461666e-15,  1.54128759e+00, ...,\n",
      "         1.47139985e+00,  1.58389987e+00,  1.52601681e+00],\n",
      "       [-2.08073204e-01, -1.41397972e-24,  1.44356726e+00, ...,\n",
      "         1.49567987e+00,  1.57518282e+00,  1.83780006e+00],\n",
      "       [-6.80136026e-02,  6.30763086e-24,  1.67302188e+00, ...,\n",
      "         1.74681280e+00,  1.82410437e+00,  1.87783016e+00]]), array([[-3.16070918e-01],\n",
      "       [-3.86528326e-04],\n",
      "       [ 1.88219761e+00],\n",
      "       [-1.85889651e-01],\n",
      "       [-1.84153514e-01],\n",
      "       [-9.55311401e-02],\n",
      "       [ 2.07679719e+00],\n",
      "       [ 1.85152858e+00],\n",
      "       [ 2.07389988e+00],\n",
      "       [-1.55532518e-01],\n",
      "       [ 1.77468499e+00],\n",
      "       [ 7.07817359e-23],\n",
      "       [-7.42144318e-02],\n",
      "       [-3.00685205e-01],\n",
      "       [-8.95937421e-03],\n",
      "       [-9.43609783e-24],\n",
      "       [-2.55053577e-01],\n",
      "       [-1.70926173e-25],\n",
      "       [ 1.29411595e+00],\n",
      "       [ 1.74256930e+00],\n",
      "       [ 3.45807211e-24],\n",
      "       [ 1.80852292e+00],\n",
      "       [ 1.21430865e-02],\n",
      "       [ 7.45938903e-07],\n",
      "       [-1.65613493e-02],\n",
      "       [ 1.91080218e+00],\n",
      "       [-1.14966726e-06],\n",
      "       [ 1.75542185e+00],\n",
      "       [ 5.69583701e-24],\n",
      "       [-6.26285766e-24],\n",
      "       [-1.07708183e-01],\n",
      "       [ 1.81704226e+00],\n",
      "       [ 1.82925918e+00],\n",
      "       [ 1.82857809e+00],\n",
      "       [ 1.81025303e+00],\n",
      "       [-9.16171390e-02],\n",
      "       [ 1.78965296e+00],\n",
      "       [-2.23105105e-01],\n",
      "       [-1.45566876e-01],\n",
      "       [ 1.97387059e+00],\n",
      "       [-7.84963012e-13],\n",
      "       [-3.13241503e-02],\n",
      "       [ 1.93119811e+00],\n",
      "       [ 1.77452359e+00],\n",
      "       [ 2.05140254e+00],\n",
      "       [-1.73799902e-01],\n",
      "       [-2.10376558e-01],\n",
      "       [ 1.90487288e+00],\n",
      "       [ 1.87281955e+00],\n",
      "       [ 1.74663714e+00]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "url = r'https://raw.githubusercontent.com/AnnaShestova/salary-years-simple-linear-regression/master/Salary_Data.csv'\n",
    "data = pd.read_csv(url)\n",
    "#print(dataset.head())\n",
    "\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, 1].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "#Оценка качества модели:\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 score: %.2f\" % r2_score(y_test, y_pred))\n",
    "\n",
    "#Получение информации о количестве слоев и нейронов в каждом слое:\n",
    "print(mlp.n_layers_) # количество слоев\n",
    "print(mlp.hidden_layer_sizes) # количество нейронов в каждом скрытом слое\n",
    "#Получение значения весов и смещений для каждого слоя: \n",
    "print(mlp.coefs_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
